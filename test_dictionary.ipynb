{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/sample/train.csv\")\n",
    "train_df[\"korean\"].to_csv(\"data/sample/train.ko\", index=False)\n",
    "train_df[\"english\"].to_csv(\"data/sample/train.en\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv(\"data/sample/valid.csv\")\n",
    "valid_df[\"korean\"].to_csv(\"data/sample/valid.ko\", index=False)\n",
    "valid_df[\"english\"].to_csv(\"data/sample/valid.en\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from nlp.datasets.data_helper import create_or_load_tokenizer\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "[592, 82, 26, 1748, 1673, 858, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "50\n",
      "['▁안녕하세요', '▁저는', '▁이', '승', '채', '▁입니다', '.', '.']\n",
      "안녕하세요 저는 이승채 입니다..\n"
     ]
    }
   ],
   "source": [
    "ko_vocab = create_or_load_tokenizer(\n",
    "    file_path=\"data/sample/train.ko\",\n",
    "    save_path=\"dictionary/sample\",\n",
    "    language=\"ko\",\n",
    "    vocab_size=8000,\n",
    "    tokenizer_type=\"unigram\"\n",
    ")\n",
    "print(ko_vocab.GetPieceSize())\n",
    "text = \"안녕하세요 저는 Estsoft의 정환석입니다.\"\n",
    "idx_lst = ko_vocab.EncodeAsIds(text)\n",
    "print(idx_lst + [4] * (50 - len(idx_lst)))\n",
    "print(len(idx_lst + [4] * (50 - len(idx_lst))))\n",
    "print(ko_vocab.EncodeAsPieces(text))\n",
    "print(ko_vocab.DecodeIds(idx_lst))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "en_vocab = create_or_load_tokenizer(\n",
    "    file_path=\"data/sample/train.en\",\n",
    "    save_path=\"dictionary/sample\",\n",
    "    language=\"en\",\n",
    "    vocab_size=8000,\n",
    "    tokenizer_type=\"unigram\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "[952, 69, 408, 17, 23, 2]\n",
      "['▁Hello', '▁my', '▁name', '▁is', '▁', '이승채']\n",
      "Hello my name is  ⁇ \n"
     ]
    }
   ],
   "source": [
    "print(en_vocab.GetPieceSize())\n",
    "text = \"Hello my name is 이승채\"\n",
    "idx_lst = en_vocab.EncodeAsIds(text)\n",
    "print(idx_lst)\n",
    "print(en_vocab.EncodeAsPieces(text))\n",
    "print(en_vocab.DecodeIds(idx_lst))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=data/sample/train.ko --model_prefix=ko_corpus_8000 --model_type=bpe --vocab_size=8000 --bos_id=0 --eos_id=1 --unk_id=2 --pad_id=3\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: data/sample/train.ko\n",
      "  input_format: \n",
      "  model_prefix: ko_corpus_8000\n",
      "  model_type: BPE\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: 0\n",
      "  eos_id: 1\n",
      "  pad_id: 3\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(181) LOG(INFO) Loading corpus: data/sample/train.ko\n",
      "trainer_interface.cc(406) LOG(INFO) Loaded all 100001 sentences\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(536) LOG(INFO) all chars count=2809153\n",
      "trainer_interface.cc(547) LOG(INFO) Done: 99.9503% characters are covered.\n",
      "trainer_interface.cc(557) LOG(INFO) Alphabet size=1284\n",
      "trainer_interface.cc(558) LOG(INFO) Final character coverage=0.999503\n",
      "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 100001 sentences.\n",
      "trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 100001\n",
      "trainer_interface.cc(607) LOG(INFO) Done! 141887\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=51970 min_freq=119\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7731 size=20 all=48570 active=4721 piece=▁하\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4104 size=40 all=51327 active=7478 piece=▁거\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3383 size=60 all=52927 active=9078 piece=▁내\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2662 size=80 all=54084 active=10235 piece=▁여\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2332 size=100 all=55341 active=11492 piece=▁방\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2297 min_freq=93\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2004 size=120 all=56523 active=3881 piece=▁주문\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1853 size=140 all=57777 active=5135 piece=까지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1623 size=160 all=58854 active=6212 piece=렇게\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1486 size=180 all=60134 active=7492 piece=▁맞\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1392 size=200 all=61411 active=8769 piece=▁너\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1389 min_freq=80\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1233 size=220 all=62380 active=4009 piece=하지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1164 size=240 all=63263 active=4892 piece=▁불\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1073 size=260 all=64200 active=5829 piece=하면\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1006 size=280 all=65139 active=6768 piece=▁달\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=958 size=300 all=65984 active=7613 piece=▁뭐\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=955 min_freq=70\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=912 size=320 all=66464 active=3753 piece=▁프로\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=857 size=340 all=67187 active=4476 piece=▁경우\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=798 size=360 all=67778 active=5067 piece=▁드리\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=745 size=380 all=68843 active=6132 piece=▁했\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=710 size=400 all=69475 active=6764 piece=▁과\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=710 min_freq=64\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=684 size=420 all=70364 active=4310 piece=▁살\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=641 size=440 all=71132 active=5078 piece=▁남\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=615 size=460 all=72156 active=6102 piece=▁가능한\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=591 size=480 all=72762 active=6708 piece=▁시작\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=555 size=500 all=73370 active=7316 piece=▁죄송\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=555 min_freq=59\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=539 size=520 all=74112 active=4403 piece=게요\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=518 size=540 all=74882 active=5173 piece=하시는\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=497 size=560 all=75769 active=6060 piece=스템\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=477 size=580 all=76445 active=6736 piece=▁향\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=465 size=600 all=77071 active=7362 piece=▁안전\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=465 min_freq=54\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=445 size=620 all=77825 active=4569 piece=▁필요한\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=430 size=640 all=78412 active=5156 piece=▁잠\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=421 size=660 all=79217 active=5961 piece=▁되었습니다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=400 size=680 all=79781 active=6525 piece=▁있었\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=387 size=700 all=80487 active=7231 piece=▁답변\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=387 min_freq=49\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=373 size=720 all=81092 active=4607 piece=▁제품이\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=358 size=740 all=81848 active=5363 piece=▁면\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=349 size=760 all=82456 active=5971 piece=▁건강\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=341 size=780 all=83019 active=6534 piece=▁드릴\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=332 size=800 all=83870 active=7385 piece=▁처음\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=331 min_freq=46\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=323 size=820 all=84510 active=4816 piece=▁우리의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=314 size=840 all=84931 active=5237 piece=▁해서\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=306 size=860 all=85399 active=5705 piece=OK\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=300 size=880 all=86011 active=6317 piece=▁당신은\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=294 size=900 all=86373 active=6679 piece=▁일반\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=294 min_freq=43\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=286 size=920 all=86919 active=4852 piece=▁보여\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=278 size=940 all=87480 active=5413 piece=▁라\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=271 size=960 all=88314 active=6247 piece=사가\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=264 size=980 all=88915 active=6848 piece=▁빠르\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=260 size=1000 all=89535 active=7468 piece=▁회사에서\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=259 min_freq=41\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=254 size=1020 all=90007 active=4947 piece=▁소개해\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=247 size=1040 all=90452 active=5392 piece=▁솔\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=244 size=1060 all=91048 active=5988 piece=▁저희에게\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=237 size=1080 all=91514 active=6454 piece=▁소프트웨어\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=231 size=1100 all=92070 active=7010 piece=▁있으시면\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=230 min_freq=38\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=226 size=1120 all=92468 active=5002 piece=▁분야\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=223 size=1140 all=92997 active=5531 piece=겠습니까\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=218 size=1160 all=93465 active=5999 piece=시다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=215 size=1180 all=93843 active=6377 piece=▁수출\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=211 size=1200 all=94536 active=7070 piece=▁요구\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=211 min_freq=36\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=207 size=1220 all=95031 active=5195 piece=▁즉\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=202 size=1240 all=95496 active=5660 piece=려면\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=200 size=1260 all=96000 active=6164 piece=▁기다리\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=197 size=1280 all=96563 active=6727 piece=▁저희도\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=193 size=1300 all=96949 active=7113 piece=▁난\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=193 m"
     ]
    }
   ],
   "source": [
    "ko_vocab_bpe = create_or_load_tokenizer(\n",
    "    file_path=\"data/sample/train.ko\",\n",
    "    save_path=\"dictionary/sample_bpe\",\n",
    "    language=\"ko\",\n",
    "    vocab_size=8000,\n",
    "    tokenizer_type=\"bpe\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "[844, 207, 10, 7180, 7121, 781, 6717]\n",
      "['▁안녕하세요', '▁저는', '▁이', '승', '채', '▁입니다', '.']\n",
      "안녕하세요 저는 이승채 입니다.\n"
     ]
    }
   ],
   "source": [
    "print(ko_vocab_bpe.GetPieceSize())\n",
    "text = \"안녕하세요 저는 이승채 입니다.\"\n",
    "idx_lst = ko_vocab_bpe.EncodeAsIds(text)\n",
    "print(idx_lst)\n",
    "print(ko_vocab_bpe.EncodeAsPieces(text))\n",
    "print(ko_vocab_bpe.DecodeIds(idx_lst))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "ko_vocab_char = create_or_load_tokenizer(\n",
    "    file_path=\"data/sample/train.ko\",\n",
    "    save_path=\"dictionary/sample_char\",\n",
    "    language=\"ko\",\n",
    "    vocab_size=8000,\n",
    "    tokenizer_type=\"char\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288\n",
      "[4, 76, 289, 10, 73, 17, 4, 41, 11, 4, 8, 468, 409, 4, 50, 7, 6, 5]\n",
      "['▁', '안', '녕', '하', '세', '요', '▁', '저', '는', '▁', '이', '승', '채', '▁', '입', '니', '다', '.']\n",
      "안녕하세요 저는 이승채 입니다.\n"
     ]
    }
   ],
   "source": [
    "print(ko_vocab_char.GetPieceSize())\n",
    "text = \"안녕하세요 저는 Estsoft의 정환석입니다.\"\n",
    "idx_lst = ko_vocab_char.EncodeAsIds(text)\n",
    "print(idx_lst)\n",
    "print(ko_vocab_char.EncodeAsPieces(text))\n",
    "print(ko_vocab_char.DecodeIds(idx_lst))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "ko_vocab_word = create_or_load_tokenizer(\n",
    "    file_path=\"data/sample/train.ko\",\n",
    "    save_path=\"dictionary/sample_word\",\n",
    "    language=\"ko\",\n",
    "    vocab_size=8000,\n",
    "    tokenizer_type=\"word\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "[720, 23, 2]\n",
      "['▁안녕하세요', '▁저는', '▁이승채▁입니다..']\n",
      "안녕하세요 저는 ⁇ \n"
     ]
    }
   ],
   "source": [
    "print(ko_vocab_word.GetPieceSize())\n",
    "text = \"안녕하세요 저는 이승채 입니다..\"\n",
    "idx_lst = ko_vocab_word.EncodeAsIds(text)\n",
    "print(idx_lst)\n",
    "print(ko_vocab_word.EncodeAsPieces(text))\n",
    "print(ko_vocab_word.DecodeIds(idx_lst))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from nlp.datasets.data_helper import TrainDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "not equal src_data, trg_data line size",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 9\u001B[0m\n\u001B[1;32m      1\u001B[0m dataset \u001B[38;5;241m=\u001B[39m TrainDataset(\n\u001B[1;32m      2\u001B[0m         x_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/sample/train.ko\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m         src_vocab\u001B[38;5;241m=\u001B[39mko_vocab,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      6\u001B[0m         max_sequence_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m\n\u001B[1;32m      7\u001B[0m     )\n\u001B[0;32m----> 9\u001B[0m sampler \u001B[38;5;241m=\u001B[39m \u001B[43mRandomSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m loader \u001B[38;5;241m=\u001B[39m DataLoader(dataset\u001B[38;5;241m=\u001B[39mdataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, sampler\u001B[38;5;241m=\u001B[39msampler)\n",
      "File \u001B[0;32m~/.conda/envs/scratch_study/lib/python3.8/site-packages/torch/utils/data/sampler.py:106\u001B[0m, in \u001B[0;36mRandomSampler.__init__\u001B[0;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement, \u001B[38;5;28mbool\u001B[39m):\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement should be a boolean value, but got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    104\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement))\n\u001B[0;32m--> 106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_samples\u001B[49m, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_samples should be a positive integer \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    108\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue, but got num_samples=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples))\n",
      "File \u001B[0;32m~/.conda/envs/scratch_study/lib/python3.8/site-packages/torch/utils/data/sampler.py:114\u001B[0m, in \u001B[0;36mRandomSampler.num_samples\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnum_samples\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;66;03m# dataset size might change at runtime\u001B[39;00m\n\u001B[1;32m    113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_samples \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 114\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_source\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_samples\n",
      "File \u001B[0;32m~/PycharmProjects/scratch_study/nlp/datasets/data_helper.py:96\u001B[0m, in \u001B[0;36mTrainDataset.__len__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__len__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msrc_data) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrg_data):\n\u001B[0;32m---> 96\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnot equal src_data, trg_data line size\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msrc_data)\n",
      "\u001B[0;31mIndexError\u001B[0m: not equal src_data, trg_data line size"
     ]
    }
   ],
   "source": [
    "dataset = TrainDataset(\n",
    "    x_path='data/sample/train_ko',\n",
    "    src_vocab=ko_vocab,\n",
    "    y_path='data/sample/train_en',\n",
    "    trg_vocab=en_vocab,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "sampler = RandomSampler(dataset)\n",
    "loader = DataLoader(dataset=dataset , batch_size=1,sampler=sampler)\n",
    "for i in loader:\n",
    "    print(i)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m idx \u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[43mloader\u001B[49m:\n\u001B[1;32m      3\u001B[0m     encoder_input, decoder_input, decoder_output \u001B[38;5;241m=\u001B[39m i\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(encoder_input)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
